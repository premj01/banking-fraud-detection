{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55bd7676",
   "metadata": {},
   "source": [
    "# Financial Transaction Fraud Detection System\n",
    "## Real-time Suspicious Activity Detection with ML Models\n",
    "\n",
    "This notebook implements a comprehensive fraud detection system with:\n",
    "- **3 ML Models**: Isolation Forest, Random Forest, XGBoost\n",
    "- **Real-time Scoring**: Stream-based transaction validation\n",
    "- **Visualization**: Transaction patterns, fraud distribution, model comparison\n",
    "- **Explainability**: SHAP values for fraud reasons\n",
    "- **Monitoring**: Drift detection and performance tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6213d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (confusion_matrix, classification_report, \n\u001b[32m     15\u001b[39m                              roc_auc_score, auc, roc_curve, precision_recall_curve)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshap\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjoblib\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "# 1. ENVIRONMENT SETUP & IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, \n",
    "                             roc_auc_score, auc, roc_curve, precision_recall_curve)\n",
    "import shap\n",
    "import joblib\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úì All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7dddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. LOAD DATASET & QUICK SANITY CHECKS\n",
    "file_path = r\"c:\\Users\\ringa\\OneDrive\\Desktop\\project\\new\\Copy of Sample_DATA.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nColumn Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nFraud Class Distribution:\")\n",
    "print(df['fraud'].value_counts())\n",
    "print(f\"Fraud Rate: {df['fraud'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe1a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. DATA PREPROCESSING & CLEANING\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Parse DateTime\n",
    "df_clean['DateTime'] = pd.to_datetime(df_clean['Date'] + ' ' + df_clean['Time'], \n",
    "                                       format='%d/%m/%y %I:%M:%S %p', errors='coerce')\n",
    "\n",
    "# Fill missing datetime with current time\n",
    "df_clean['DateTime'].fillna(pd.Timestamp.now(), inplace=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "drop_cols = ['Transaction_ID', 'Date', 'Time', 'Merchant_ID', 'Customer_ID', 'Device_ID', 'IP_Address']\n",
    "df_clean = df_clean.drop(columns=drop_cols)\n",
    "\n",
    "# Numeric columns - handle any non-numeric values\n",
    "numeric_cols = ['Transaction_Amount_Deviation', 'Days_Since_Last_Transaction', 'amount', 'Transaction_Frequency']\n",
    "for col in numeric_cols:\n",
    "    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "    df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
    "\n",
    "# Categorical columns\n",
    "categorical_cols = ['Transaction_Type', 'Payment_Gateway', 'Device_OS', \n",
    "                    'Merchant_Category', 'Transaction_Channel', 'Transaction_Status']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df_clean[col] = df_clean[col].fillna('Unknown')\n",
    "\n",
    "print(\"‚úì Data Cleaning Complete\")\n",
    "print(f\"Dataset shape after cleaning: {df_clean.shape}\")\n",
    "print(f\"\\nData Info:\")\n",
    "print(df_clean.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9171e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. FEATURE ENGINEERING\n",
    "df_features = df_clean.copy()\n",
    "\n",
    "# Time-based features\n",
    "df_features['hour'] = df_features['DateTime'].dt.hour\n",
    "df_features['day_of_week'] = df_features['DateTime'].dt.dayofweek\n",
    "df_features['day_of_month'] = df_features['DateTime'].dt.day\n",
    "df_features['month'] = df_features['DateTime'].dt.month\n",
    "\n",
    "# Risk indicators from existing features\n",
    "df_features['is_high_amount'] = (df_features['amount'] > df_features['amount'].quantile(0.75)).astype(int)\n",
    "df_features['is_low_frequency'] = (df_features['Transaction_Frequency'] <= 2).astype(int)\n",
    "df_features['amount_deviation_high'] = (abs(df_features['Transaction_Amount_Deviation']) > 50).astype(int)\n",
    "df_features['failed_status'] = (df_features['Transaction_Status'] == 'Failed').astype(int)\n",
    "df_features['pending_status'] = (df_features['Transaction_Status'] == 'Pending').astype(int)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_features[col + '_encoded'] = le.fit_transform(df_features[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(\"‚úì Feature Engineering Complete\")\n",
    "print(f\"Total Features: {df_features.shape[1]}\")\n",
    "print(f\"\\nNew engineered features:\")\n",
    "engineered_features = ['hour', 'day_of_week', 'day_of_month', 'month', \n",
    "                       'is_high_amount', 'is_low_frequency', 'amount_deviation_high',\n",
    "                       'failed_status', 'pending_status']\n",
    "print(engineered_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc0fdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. PREPARE TRAINING DATA & SPLIT\n",
    "# Select features for modeling\n",
    "feature_cols = (numeric_cols + engineered_features + \n",
    "                [col + '_encoded' for col in categorical_cols])\n",
    "\n",
    "X = df_features[feature_cols].fillna(0)\n",
    "y = df_features['fraud']\n",
    "\n",
    "# Time-based split (to avoid data leakage)\n",
    "split_point = int(len(X) * 0.7)\n",
    "split_point_val = int(len(X) * 0.85)\n",
    "\n",
    "X_train, y_train = X.iloc[:split_point], y.iloc[:split_point]\n",
    "X_val, y_val = X.iloc[split_point:split_point_val], y.iloc[split_point:split_point_val]\n",
    "X_test, y_test = X.iloc[split_point_val:], y.iloc[split_point_val:]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"‚úì Data Split Complete\")\n",
    "print(f\"Training set: {X_train.shape} | Fraud rate: {y_train.mean()*100:.2f}%\")\n",
    "print(f\"Validation set: {X_val.shape} | Fraud rate: {y_val.mean()*100:.2f}%\")\n",
    "print(f\"Test set: {X_test.shape} | Fraud rate: {y_test.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978dc1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. EXPLORATORY DATA ANALYSIS & VISUALIZATIONS\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Transaction Amount Distribution\n",
    "axes[0, 0].hist(df_features[df_features['fraud']==0]['amount'], bins=50, alpha=0.7, label='Legitimate', color='green')\n",
    "axes[0, 0].hist(df_features[df_features['fraud']==1]['amount'], bins=50, alpha=0.7, label='Fraudulent', color='red')\n",
    "axes[0, 0].set_xlabel('Transaction Amount')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Transaction Amount Distribution by Fraud Status')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Fraud Rate by Transaction Type\n",
    "fraud_by_type = df_features.groupby('Transaction_Type')['fraud'].agg(['sum', 'count'])\n",
    "fraud_by_type['rate'] = fraud_by_type['sum'] / fraud_by_type['count']\n",
    "axes[0, 1].barh(fraud_by_type.index, fraud_by_type['rate'], color='coral')\n",
    "axes[0, 1].set_xlabel('Fraud Rate')\n",
    "axes[0, 1].set_title('Fraud Rate by Transaction Type')\n",
    "\n",
    "# Transaction Status vs Fraud\n",
    "status_fraud = pd.crosstab(df_features['Transaction_Status'], df_features['fraud'])\n",
    "status_fraud.plot(kind='bar', ax=axes[1, 0], color=['green', 'red'])\n",
    "axes[1, 0].set_title('Transaction Status vs Fraud')\n",
    "axes[1, 0].set_xlabel('Status')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].legend(['Legitimate', 'Fraud'])\n",
    "\n",
    "# Fraud by Hour of Day\n",
    "fraud_by_hour = df_features.groupby('hour')['fraud'].mean()\n",
    "axes[1, 1].plot(fraud_by_hour.index, fraud_by_hour.values, marker='o', color='purple')\n",
    "axes[1, 1].set_xlabel('Hour of Day')\n",
    "axes[1, 1].set_ylabel('Fraud Rate')\n",
    "axes[1, 1].set_title('Fraud Rate by Hour of Day')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(r'c:\\Users\\ringa\\OneDrive\\Desktop\\project\\new\\eda_visualizations.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì EDA Visualizations Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfceaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. CORRELATION HEATMAP\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "numeric_features = numeric_cols + engineered_features\n",
    "correlation = df_features[numeric_features + ['fraud']].corr()\n",
    "sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm', center=0, ax=ax, cbar_kws={'label': 'Correlation'})\n",
    "ax.set_title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig(r'c:\\Users\\ringa\\OneDrive\\Desktop\\project\\new\\correlation_heatmap.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Correlation Analysis Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58bb53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. MODEL 1: ISOLATION FOREST (UNSUPERVISED ANOMALY DETECTION)\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL 1: ISOLATION FOREST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "iso_forest = IsolationForest(\n",
    "    contamination=y_train.mean(),  # Set contamination to match fraud rate\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train on full training data\n",
    "iso_forest.fit(X_train_scaled)\n",
    "\n",
    "# Predictions (1 for normal, -1 for anomaly)\n",
    "y_train_iso = iso_forest.predict(X_train_scaled)\n",
    "y_val_iso = iso_forest.predict(X_val_scaled)\n",
    "y_test_iso = iso_forest.predict(X_test_scaled)\n",
    "\n",
    "# Convert to binary (0 for normal, 1 for anomaly)\n",
    "y_train_iso_pred = (y_train_iso == -1).astype(int)\n",
    "y_val_iso_pred = (y_val_iso == -1).astype(int)\n",
    "y_test_iso_pred = (y_test_iso == -1).astype(int)\n",
    "\n",
    "# Get anomaly scores\n",
    "train_scores = iso_forest.score_samples(X_train_scaled)\n",
    "val_scores = iso_forest.score_samples(X_val_scaled)\n",
    "test_scores = iso_forest.score_samples(X_test_scaled)\n",
    "\n",
    "print(f\"Isolation Forest - Test Set Metrics:\")\n",
    "print(f\"Accuracy: {(y_test_iso_pred == y_test).mean():.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, -test_scores):.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_test_iso_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81419c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. MODEL 2: RANDOM FOREST CLASSIFIER\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL 2: RANDOM FOREST CLASSIFIER\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    class_weight='balanced',  # Handle class imbalance\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_rf_pred = rf_model.predict(X_train_scaled)\n",
    "y_val_rf_pred = rf_model.predict(X_val_scaled)\n",
    "y_test_rf_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Probabilities for scoring\n",
    "y_train_rf_proba = rf_model.predict_proba(X_train_scaled)[:, 1]\n",
    "y_val_rf_proba = rf_model.predict_proba(X_val_scaled)[:, 1]\n",
    "y_test_rf_proba = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(f\"Random Forest - Test Set Metrics:\")\n",
    "print(f\"Accuracy: {(y_test_rf_pred == y_test).mean():.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_test_rf_proba):.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_test_rf_pred)}\")\n",
    "\n",
    "# Feature Importance\n",
    "feature_importance_rf = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 Most Important Features (Random Forest):\")\n",
    "print(feature_importance_rf.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6c5f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. MODEL 3: XGBOOST CLASSIFIER\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL 3: XGBOOST CLASSIFIER\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=len(y_train[y_train==0])/len(y_train[y_train==1]),  # Handle imbalance\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "# Train model\n",
    "xgb_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    eval_set=[(X_val_scaled, y_val)],\n",
    "    early_stopping_rounds=20,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_train_xgb_pred = xgb_model.predict(X_train_scaled)\n",
    "y_val_xgb_pred = xgb_model.predict(X_val_scaled)\n",
    "y_test_xgb_pred = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# Probabilities for scoring\n",
    "y_train_xgb_proba = xgb_model.predict_proba(X_train_scaled)[:, 1]\n",
    "y_val_xgb_proba = xgb_model.predict_proba(X_val_scaled)[:, 1]\n",
    "y_test_xgb_proba = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(f\"XGBoost - Test Set Metrics:\")\n",
    "print(f\"Accuracy: {(y_test_xgb_pred == y_test).mean():.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_test_xgb_proba):.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_test_xgb_pred)}\")\n",
    "\n",
    "# Feature Importance\n",
    "feature_importance_xgb = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 Most Important Features (XGBoost):\")\n",
    "print(feature_importance_xgb.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e721d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. MODEL COMPARISON & EVALUATION\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "models_comparison = pd.DataFrame({\n",
    "    'Model': ['Isolation Forest', 'Random Forest', 'XGBoost'],\n",
    "    'Accuracy': [\n",
    "        (y_test_iso_pred == y_test).mean(),\n",
    "        (y_test_rf_pred == y_test).mean(),\n",
    "        (y_test_xgb_pred == y_test).mean()\n",
    "    ],\n",
    "    'ROC-AUC': [\n",
    "        roc_auc_score(y_test, -test_scores),\n",
    "        roc_auc_score(y_test, y_test_rf_proba),\n",
    "        roc_auc_score(y_test, y_test_xgb_proba)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nModel Performance on Test Set:\")\n",
    "print(models_comparison.to_string(index=False))\n",
    "\n",
    "# Plot ROC curves for all models\n",
    "fpr_iso, tpr_iso, _ = roc_curve(y_test, -test_scores)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_test_rf_proba)\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_test_xgb_proba)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ROC Curves\n",
    "ax1.plot(fpr_iso, tpr_iso, label=f\"Isolation Forest (AUC={roc_auc_score(y_test, -test_scores):.3f})\", linewidth=2)\n",
    "ax1.plot(fpr_rf, tpr_rf, label=f\"Random Forest (AUC={roc_auc_score(y_test, y_test_rf_proba):.3f})\", linewidth=2)\n",
    "ax1.plot(fpr_xgb, tpr_xgb, label=f\"XGBoost (AUC={roc_auc_score(y_test, y_test_xgb_proba):.3f})\", linewidth=2)\n",
    "ax1.plot([0, 1], [0, 1], 'k--', label='Random Classifier', alpha=0.3)\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.set_title('ROC Curves - Model Comparison')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Feature Importance Comparison\n",
    "top_features_rf = feature_importance_rf.head(8)\n",
    "top_features_xgb = feature_importance_xgb.head(8)\n",
    "\n",
    "x_pos = np.arange(len(top_features_rf))\n",
    "width = 0.35\n",
    "\n",
    "ax2.bar(x_pos - width/2, top_features_rf['importance'], width, label='Random Forest', alpha=0.8)\n",
    "ax2.bar(x_pos + width/2, top_features_xgb.iloc[:len(top_features_rf)]['importance'], width, label='XGBoost', alpha=0.8)\n",
    "ax2.set_xlabel('Features')\n",
    "ax2.set_ylabel('Importance')\n",
    "ax2.set_title('Top 8 Feature Importance Comparison')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(top_features_rf['feature'], rotation=45, ha='right')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(r'c:\\Users\\ringa\\OneDrive\\Desktop\\project\\new\\model_comparison.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Model Comparison Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e239f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. ENSEMBLE VOTING & CONSENSUS RULES\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENSEMBLE VOTING STRATEGY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Simple voting ensemble (majority voting)\n",
    "ensemble_votes = (y_test_iso_pred + y_test_rf_pred + y_test_xgb_pred)\n",
    "ensemble_pred = (ensemble_votes >= 2).astype(int)  # Flag if at least 2 models vote fraud\n",
    "\n",
    "print(f\"Ensemble (Voting) - Test Set Metrics:\")\n",
    "print(f\"Accuracy: {(ensemble_pred == y_test).mean():.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, ensemble_votes):.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, ensemble_pred)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, ensemble_pred)}\")\n",
    "\n",
    "# Weighted average of probabilities (for probability-based models)\n",
    "ensemble_proba_weighted = (0.3 * y_test_rf_proba + 0.7 * y_test_xgb_proba)  # Favor XGBoost\n",
    "ensemble_pred_proba = (ensemble_proba_weighted >= 0.5).astype(int)\n",
    "\n",
    "print(f\"\\nEnsemble (Weighted Probability) - Test Set Metrics:\")\n",
    "print(f\"Accuracy: {(ensemble_pred_proba == y_test).mean():.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, ensemble_proba_weighted):.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, ensemble_pred_proba)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f92cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. REAL-TIME SCORING ENGINE & FLAGGING LOGIC\n",
    "class RealTimeTransactionScorer:\n",
    "    \\\"\\\"\\\"Real-time fraud detection scoring engine with multiple models and thresholding\\\"\\\"\\\"\\n\n",
    "    def __init__(self, iso_forest, rf_model, xgb_model, scaler, threshold=0.5):\n",
    "        self.iso_forest = iso_forest\n",
    "        self.rf_model = rf_model\n",
    "        self.xgb_model = xgb_model\n",
    "        self.scaler = scaler\n",
    "        self.threshold = threshold\n",
    "        self.flagged_transactions = []\n",
    "        \n",
    "    def score_transaction(self, transaction_features):\n",
    "        \\\"\\\"\\\"Score a single transaction using ensemble approach\\\"\\\"\\\"\\n\n",
    "        # Scale features\n",
    "        features_scaled = self.scaler.transform(transaction_features.reshape(1, -1))\n",
    "        \n",
    "        # Model 1: Isolation Forest (anomaly score)\n",
    "        iso_score = -self.iso_forest.score_samples(features_scaled)[0]\n",
    "        iso_pred = (iso_score > 0.5).astype(int)\n",
    "        \n",
    "        # Model 2: Random Forest (probability)\n",
    "        rf_proba = self.rf_model.predict_proba(features_scaled)[0, 1]\n",
    "        rf_pred = (rf_proba >= self.threshold).astype(int)\n",
    "        \n",
    "        # Model 3: XGBoost (probability)\n",
    "        xgb_proba = self.xgb_model.predict_proba(features_scaled)[0, 1]\n",
    "        xgb_pred = (xgb_proba >= self.threshold).astype(int)\n",
    "        \n",
    "        # Ensemble: consensus voting\n",
    "        ensemble_score = (iso_pred + rf_pred + xgb_pred) / 3  # Average of predictions\n",
    "        ensemble_pred = int(ensemble_score >= 0.66)  # Flag if consensus is strong\n",
    "        \n",
    "        return {\n",
    "            'iso_score': iso_score,\n",
    "            'rf_proba': rf_proba,\n",
    "            'xgb_proba': xgb_proba,\n",
    "            'ensemble_score': ensemble_score,\n",
    "            'is_flagged': ensemble_pred,\n",
    "            'confidence': max(iso_score, rf_proba, xgb_proba)\n",
    "        }\n",
    "    \n",
    "    def flag_suspicious_transaction(self, transaction_id, features, scores):\n",
    "        \\\"\\\"\\\"Log flagged transaction for review\\\"\\\"\\\"\\n\n",
    "        flag_record = {\n",
    "            'timestamp': datetime.now(),\n",
    "            'transaction_id': transaction_id,\n",
    "            'scores': scores,\n",
    "            'action': 'FLAG_FOR_REVIEW'\n",
    "        }\n",
    "        self.flagged_transactions.append(flag_record)\n",
    "        return flag_record\n",
    "\n",
    "# Initialize scorer with trained models\n",
    "scorer = RealTimeTransactionScorer(\n",
    "    iso_forest=iso_forest,\n",
    "    rf_model=rf_model,\n",
    "    xgb_model=xgb_model,\n",
    "    scaler=scaler,\n",
    "    threshold=0.5\n",
    ")\n",
    "\n",
    "print(\\\"‚úì Real-Time Scoring Engine Initialized\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99bab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. REAL-TIME STREAMING SIMULATION\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"REAL-TIME TRANSACTION STREAMING SIMULATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Simulate real-time scoring on test set\n",
    "real_time_results = []\n",
    "\n",
    "for idx, (i, row) in enumerate(X_test.iterrows()):\n",
    "    features = row.values\n",
    "    scores = scorer.score_transaction(features)\n",
    "    \n",
    "    result = {\n",
    "        'transaction_idx': i,\n",
    "        'actual_fraud': y_test.iloc[idx],\n",
    "        'flagged': scores['is_flagged'],\n",
    "        'iso_score': scores['iso_score'],\n",
    "        'rf_proba': scores['rf_proba'],\n",
    "        'xgb_proba': scores['xgb_proba'],\n",
    "        'ensemble_score': scores['ensemble_score'],\n",
    "        'confidence': scores['confidence']\n",
    "    }\n",
    "    real_time_results.append(result)\n",
    "    \n",
    "    if scores['is_flagged']:\n",
    "        scorer.flag_suspicious_transaction(f\\\"TXN_{i}\\\", features, scores)\n",
    "\n",
    "# Convert to DataFrame\n",
    "real_time_df = pd.DataFrame(real_time_results)\n",
    "\n",
    "print(f\"‚úì Processed {len(real_time_df)} transactions in real-time simulation\")\n",
    "print(f\"Flagged Transactions: {real_time_df['flagged'].sum()}\")\n",
    "print(f\"True Fraud Cases: {real_time_df['actual_fraud'].sum()}\")\n",
    "print(f\"\\nReal-time Detection Rate: {real_time_df['flagged'].mean()*100:.2f}%\")\n",
    "print(f\"Actual Fraud Rate: {real_time_df['actual_fraud'].mean()*100:.2f}%\")\n",
    "\n",
    "# Performance metrics\n",
    "print(f\"\\nReal-time Performance on Test Set:\")\n",
    "print(f\\\"Accuracy: {(real_time_df['flagged'] == real_time_df['actual_fraud']).mean():.4f}\\\")\n",
    "print(f\\\"ROC-AUC: {roc_auc_score(real_time_df['actual_fraud'], real_time_df['ensemble_score']):.4f}\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c8ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. FLAGGED TRANSACTIONS ANALYSIS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FLAGGED TRANSACTIONS ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Filter flagged transactions\n",
    "flagged_mask = real_time_df['flagged'] == 1\n",
    "\n",
    "print(f\"\\nFlagged Transaction Summary:\")\n",
    "print(f\"Total Flagged: {flagged_mask.sum()}\")\n",
    "print(f\"True Positives (Correct Flags): {((real_time_df['flagged']==1) & (real_time_df['actual_fraud']==1)).sum()}\")\n",
    "print(f\"False Positives (Incorrect Flags): {((real_time_df['flagged']==1) & (real_time_df['actual_fraud']==0)).sum()}\")\n",
    "print(f\\\"False Negative (Missed Fraud): {((real_time_df['flagged']==0) & (real_time_df['actual_fraud']==1)).sum()}\\\")\n",
    "\n",
    "# Show high-confidence flagged transactions\n",
    "high_confidence_flagged = real_time_df[\n",
    "    (real_time_df['flagged']==1) & (real_time_df['confidence'] > 0.7)\n",
    "].sort_values('confidence', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 High-Confidence Flagged Transactions:\")\n",
    "print(high_confidence_flagged[['transaction_idx', 'actual_fraud', 'rf_proba', 'xgb_proba', 'confidence']].head(10))\n",
    "\n",
    "# Visualize real-time detection\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Distribution of ensemble scores\n",
    "axes[0, 0].hist(real_time_df[real_time_df['actual_fraud']==0]['ensemble_score'], bins=30, alpha=0.7, label='Legitimate', color='green')\n",
    "axes[0, 0].hist(real_time_df[real_time_df['actual_fraud']==1]['ensemble_score'], bins=30, alpha=0.7, label='Fraudulent', color='red')\n",
    "axes[0, 0].axvline(0.66, color='black', linestyle='--', label='Threshold')\n",
    "axes[0, 0].set_xlabel('Ensemble Score')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Distribution of Ensemble Fraud Scores')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Model probability comparison\n",
    "axes[0, 1].scatter(real_time_df[real_time_df['actual_fraud']==0]['rf_proba'], \n",
    "                   real_time_df[real_time_df['actual_fraud']==0]['xgb_proba'],\n",
    "                   alpha=0.5, s=20, label='Legitimate', color='green')\n",
    "axes[0, 1].scatter(real_time_df[real_time_df['actual_fraud']==1]['rf_proba'], \n",
    "                   real_time_df[real_time_df['actual_fraud']==1]['xgb_proba'],\n",
    "                   alpha=0.5, s=20, label='Fraudulent', color='red')\n",
    "axes[0, 1].set_xlabel('Random Forest Probability')\n",
    "axes[0, 1].set_ylabel('XGBoost Probability')\n",
    "axes[0, 1].set_title('Model Agreement - RF vs XGBoost')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "cm = confusion_matrix(real_time_df['actual_fraud'], real_time_df['flagged'])\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 0], cbar=False)\n",
    "axes[1, 0].set_xlabel('Predicted')\n",
    "axes[1, 0].set_ylabel('Actual')\n",
    "axes[1, 0].set_title('Confusion Matrix - Real-time Detection')\n",
    "\n",
    "# Flagged vs Not Flagged\n",
    "status = pd.DataFrame({\n",
    "    'Status': ['Flagged', 'Not Flagged'],\n",
    "    'Fraud Cases': [\n",
    "        ((real_time_df['flagged']==1) & (real_time_df['actual_fraud']==1)).sum(),\n",
    "        ((real_time_df['flagged']==0) & (real_time_df['actual_fraud']==1)).sum()\n",
    "    ],\n",
    "    'Legitimate Cases': [\n",
    "        ((real_time_df['flagged']==1) & (real_time_df['actual_fraud']==0)).sum(),\n",
    "        ((real_time_df['flagged']==0) & (real_time_df['actual_fraud']==0)).sum()\n",
    "    ]\n",
    "})\n",
    "status.set_index('Status')[['Fraud Cases', 'Legitimate Cases']].plot(kind='bar', ax=axes[1, 1], color=['red', 'green'])\n",
    "axes[1, 1].set_title('Flagging Results Breakdown')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "axes[1, 1].legend(title='Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(r'c:\\Users\\ringa\\OneDrive\\Desktop\\project\\new\\realtime_flagging_analysis.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\\\"‚úì Real-time Flagging Analysis Complete\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b539cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. EXPLAINABILITY - SHAP VALUES FOR XGBoost\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL EXPLAINABILITY - SHAP VALUES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create SHAP explainer for XGBoost model\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "\n",
    "# Calculate SHAP values for test set (sample for performance)\n",
    "sample_size = min(100, len(X_test_scaled))\n",
    "shap_values = explainer.shap_values(X_test_scaled[:sample_size])\n",
    "\n",
    "# Summary plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values, X_test_scaled[:sample_size], feature_names=feature_cols, plot_type=\"bar\", show=False)\n",
    "plt.title(\"SHAP Feature Importance - XGBoost Model\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(r'c:\\Users\\ringa\\OneDrive\\Desktop\\project\\new\\shap_feature_importance.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì SHAP Feature Importance Visualization Complete\")\n",
    "\n",
    "# Feature importance summary\n",
    "feature_names_arr = np.array(feature_cols)\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "top_features = feature_names_arr[np.argsort(mean_abs_shap)[-10:]][::-1]\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features (SHAP):\")\n",
    "for i, feat in enumerate(top_features, 1):\n",
    "    print(f\"{i}. {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b439b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. MODEL PERSISTENCE & SAVING\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING TRAINED MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_dir = r'c:\\Users\\ringa\\OneDrive\\Desktop\\project\\new\\models'\n",
    "import os\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save models\n",
    "joblib.dump(iso_forest, os.path.join(model_dir, 'isolation_forest_model.pkl'))\n",
    "joblib.dump(rf_model, os.path.join(model_dir, 'random_forest_model.pkl'))\n",
    "joblib.dump(xgb_model, os.path.join(model_dir, 'xgboost_model.pkl'))\n",
    "joblib.dump(scaler, os.path.join(model_dir, 'feature_scaler.pkl'))\n",
    "\n",
    "# Save label encoders\n",
    "joblib.dump(label_encoders, os.path.join(model_dir, 'label_encoders.pkl'))\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'models': ['isolation_forest', 'random_forest', 'xgboost'],\n",
    "    'feature_columns': feature_cols,\n",
    "    'feature_count': len(feature_cols),\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'test_performance': {\n",
    "        'isolation_forest_auc': float(roc_auc_score(y_test, -test_scores)),\n",
    "        'random_forest_auc': float(roc_auc_score(y_test, y_test_rf_proba)),\n",
    "        'xgboost_auc': float(roc_auc_score(y_test, y_test_xgb_proba))\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(model_dir, 'model_metadata.json'), 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"‚úì Models saved to {model_dir}\")\n",
    "print(f\"Files saved:\")\n",
    "print(f\"  - isolation_forest_model.pkl\")\n",
    "print(f\"  - random_forest_model.pkl\")\n",
    "print(f\"  - xgboost_model.pkl\")\n",
    "print(f\"  - feature_scaler.pkl\")\n",
    "print(f\"  - label_encoders.pkl\")\n",
    "print(f\"  - model_metadata.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f3f5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. PRODUCTION INFERENCE EXAMPLE\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PRODUCTION INFERENCE EXAMPLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load saved models\n",
    "iso_forest_prod = joblib.load(os.path.join(model_dir, 'isolation_forest_model.pkl'))\n",
    "rf_model_prod = joblib.load(os.path.join(model_dir, 'random_forest_model.pkl'))\n",
    "xgb_model_prod = joblib.load(os.path.join(model_dir, 'xgboost_model.pkl'))\n",
    "scaler_prod = joblib.load(os.path.join(model_dir, 'feature_scaler.pkl'))\n",
    "\n",
    "# Reinitialize scorer with loaded models\n",
    "scorer_prod = RealTimeTransactionScorer(\n",
    "    iso_forest=iso_forest_prod,\n",
    "    rf_model=rf_model_prod,\n",
    "    xgb_model=xgb_model_prod,\n",
    "    scaler=scaler_prod,\n",
    "    threshold=0.5\n",
    ")\n",
    "\n",
    "# Test inference on new transaction\n",
    "test_transaction = X_test.iloc[0].values\n",
    "scores = scorer_prod.score_transaction(test_transaction)\n",
    "\n",
    "print(f\"Test Transaction Scoring:\")\n",
    "print(f\"  Isolation Forest Score: {scores['iso_score']:.4f}\")\n",
    "print(f\"  Random Forest Probability: {scores['rf_proba']:.4f}\")\n",
    "print(f\"  XGBoost Probability: {scores['xgb_proba']:.4f}\")\n",
    "print(f\"  Ensemble Score: {scores['ensemble_score']:.4f}\")\n",
    "print(f\"  Is Flagged: {'YES - SUSPICIOUS' if scores['is_flagged'] else 'NO - LEGITIMATE'}\")\n",
    "print(f\"  Confidence: {scores['confidence']:.4f}\")\n",
    "\n",
    "print(\"\\n‚úì Production Inference Example Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182d0e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19. MONITORING & DRIFT DETECTION\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MONITORING & DRIFT DETECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compare training vs test distributions\n",
    "drift_metrics = {}\n",
    "\n",
    "for col in numeric_cols:\n",
    "    train_mean = X_train[col].mean()\n",
    "    test_mean = X_test[col].mean()\n",
    "    train_std = X_train[col].std()\n",
    "    test_std = X_test[col].std()\n",
    "    \n",
    "    # Calculate drift using % change\n",
    "    mean_drift = abs(test_mean - train_mean) / (abs(train_mean) + 0.001) * 100\n",
    "    std_drift = abs(test_std - train_std) / (abs(train_std) + 0.001) * 100\n",
    "    \n",
    "    drift_metrics[col] = {\n",
    "        'mean_drift_pct': mean_drift,\n",
    "        'std_drift_pct': std_drift,\n",
    "        'max_drift': max(mean_drift, std_drift)\n",
    "    }\n",
    "\n",
    "# Display high-drift features\n",
    "drift_df = pd.DataFrame(drift_metrics).T\n",
    "drift_df = drift_df.sort_values('max_drift', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Drift Analysis (Train vs Test):\")\n",
    "print(drift_df[['mean_drift_pct', 'std_drift_pct', 'max_drift']])\n",
    "\n",
    "# Alert on high drift\n",
    "high_drift_features = drift_df[drift_df['max_drift'] > 20].index.tolist()\n",
    "if high_drift_features:\n",
    "    print(f\"\\n‚ö†Ô∏è  HIGH DRIFT DETECTED in features: {high_drift_features}\")\n",
    "    print(\"   Recommendation: Retrain models with recent data\")\n",
    "else:\n",
    "    print(\"\\n‚úì No significant data drift detected\")\n",
    "\n",
    "# Model performance over time (on test set sorted by time)\n",
    "print(\"\\n\\nModel Performance Over Time (Test Set):\")\n",
    "window_size = len(real_time_df) // 5\n",
    "for i in range(5):\n",
    "    start_idx = i * window_size\n",
    "    end_idx = (i+1) * window_size if i < 4 else len(real_time_df)\n",
    "    \n",
    "    window_data = real_time_df.iloc[start_idx:end_idx]\n",
    "    auc = roc_auc_score(window_data['actual_fraud'], window_data['ensemble_score'])\n",
    "    accuracy = (window_data['flagged'] == window_data['actual_fraud']).mean()\n",
    "    \n",
    "    print(f\"  Window {i+1} (transactions {start_idx}-{end_idx}): AUC={auc:.4f}, Accuracy={accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742b9222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20. SUMMARY REPORT & RECOMMENDATIONS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FRAUD DETECTION SYSTEM - SUMMARY REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary_report = f\"\"\"\n",
    "üìä DATASET OVERVIEW\n",
    "{'='*50}\n",
    "Total Transactions: {len(df_clean)}\n",
    "Training Set: {len(X_train)} transactions\n",
    "Validation Set: {len(X_val)} transactions\n",
    "Test Set: {len(X_test)} transactions\n",
    "Overall Fraud Rate: {y.mean()*100:.2f}%\n",
    "\n",
    "ü§ñ MODEL PERFORMANCE (Test Set)\n",
    "{'='*50}\n",
    "Model 1: Isolation Forest\n",
    "  - Accuracy: {(y_test_iso_pred == y_test).mean():.4f}\n",
    "  - ROC-AUC: {roc_auc_score(y_test, -test_scores):.4f}\n",
    "  - Type: Unsupervised Anomaly Detection\n",
    "\n",
    "Model 2: Random Forest\n",
    "  - Accuracy: {(y_test_rf_pred == y_test).mean():.4f}\n",
    "  - ROC-AUC: {roc_auc_score(y_test, y_test_rf_proba):.4f}\n",
    "  - Type: Supervised Tree-based\n",
    "\n",
    "Model 3: XGBoost\n",
    "  - Accuracy: {(y_test_xgb_pred == y_test).mean():.4f}\n",
    "  - ROC-AUC: {roc_auc_score(y_test, y_test_xgb_proba):.4f}\n",
    "  - Type: Supervised Gradient Boosting\n",
    "\n",
    "üîÄ ENSEMBLE MODEL PERFORMANCE\n",
    "{'='*50}\n",
    "Voting Ensemble:\n",
    "  - Accuracy: {(ensemble_pred == y_test).mean():.4f}\n",
    "  - ROC-AUC: {roc_auc_score(y_test, ensemble_votes):.4f}\n",
    "\n",
    "Weighted Probability Ensemble:\n",
    "  - Accuracy: {(ensemble_pred_proba == y_test).mean():.4f}\n",
    "  - ROC-AUC: {roc_auc_score(y_test, ensemble_proba_weighted):.4f}\n",
    "\n",
    "üö® REAL-TIME PERFORMANCE\n",
    "{'='*50}\n",
    "Transactions Flagged: {real_time_df['flagged'].sum()} / {len(real_time_df)}\n",
    "Detection Rate: {real_time_df['flagged'].mean()*100:.2f}%\n",
    "True Positives: {((real_time_df['flagged']==1) & (real_time_df['actual_fraud']==1)).sum()}\n",
    "False Positives: {((real_time_df['flagged']==1) & (real_time_df['actual_fraud']==0)).sum()}\n",
    "False Negatives: {((real_time_df['flagged']==0) & (real_time_df['actual_fraud']==1)).sum()}\n",
    "\n",
    "‚≠ê KEY FEATURES (Top 5)\n",
    "{'='*50}\n",
    "Random Forest: {', '.join(feature_importance_rf.head(5)['feature'].values)}\n",
    "XGBoost: {', '.join(feature_importance_xgb.head(5)['feature'].values)}\n",
    "\n",
    "üí° RECOMMENDATIONS\n",
    "{'='*50}\n",
    "1. Use Weighted Probability Ensemble for production (best performance)\n",
    "2. Set threshold at 0.5-0.6 probability for optimal precision-recall\n",
    "3. Monitor for data drift monthly using reference distributions\n",
    "4. Retrain models quarterly with new labeled data\n",
    "5. Implement real-time alert system for flagged transactions\n",
    "6. Review false positives weekly to improve whitelist rules\n",
    "7. Consider transaction amount and merchant risk in manual review\n",
    "8. Use SHAP values to explain fraud flags to stakeholders\n",
    "\n",
    "üìÅ OUTPUT ARTIFACTS\n",
    "{'='*50}\n",
    "‚úì Trained Models (saved in ./models/)\n",
    "‚úì EDA Visualizations\n",
    "‚úì Model Comparison Charts\n",
    "‚úì Real-time Flagging Analysis\n",
    "‚úì SHAP Feature Importance\n",
    "‚úì Model Metadata & Versioning\n",
    "\"\"\"\n",
    "\n",
    "print(summary_report)\n",
    "\n",
    "# Save report\n",
    "report_path = r'c:\\Users\\ringa\\OneDrive\\Desktop\\project\\new\\fraud_detection_summary_report.txt'\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(summary_report)\n",
    "\n",
    "print(f\"\\n‚úì Report saved to {report_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
